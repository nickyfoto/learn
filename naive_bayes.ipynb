{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing your own Naive Bayes step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from evaluation import test\n",
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/randerson112358/Python/blob/master/Email_Spam_Detection/Email_Spam_Detection.ipynb\n",
    "\n",
    "Data Source: https://www.kaggle.com/balakishan77/spam-or-ham-email-classification/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5728, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = load_data('emails.csv')\n",
    "emails.head(5)\n",
    "emails.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates\n",
    "emails.drop_duplicates(inplace = True)\n",
    "emails.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode text using `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t3\n",
      "  (0, 4)\t2\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t4\n",
      "  (1, 1)\t1\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "message0 = 'hello world hello hello world play'\n",
    "message1 = 'test test test test one hello'\n",
    "\n",
    "#Convert a collection of text documents to a matrix of token counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform([message0, message1])\n",
    "print(bow)\n",
    "print(type(bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `CountVectorizer` returns a sparse matrix encoding our texts with the number of times a particular word occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'one', 'play', 'test', 'world']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1, 0, 2],\n",
       "       [1, 1, 0, 4, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "[vocabulary[i] for i in sorted([v for k,v in vectorizer.vocabulary_.items()])]\n",
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can see how the encoding information is saved in a sparse matrix. For `message0`, on indices [0,4,2] you have values [3,2,1].\n",
    "\n",
    "If we set `binary=True` when encoding messages, our encoder only records the whether the word is present or not, ignoring the numbber of occurance. For our first implementation of `NaiveBayes`, we will simply encode the presence of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 1)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1],\n",
       "       [1, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_b = CountVectorizer(binary=True)\n",
    "bow_b = vectorizer_b.fit_transform([message0, message1])\n",
    "print(bow_b)\n",
    "bow_b.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with MultinomialNB from sklearn\n",
    "\n",
    "Before implementing our own learner, let's check the performance of `MultinomialNB` from sklearn. Here we remove the stop_words when vectorizing our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 36996)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3462\n",
      "           1       0.99      1.00      0.99      1094\n",
      "\n",
      "    accuracy                           1.00      4556\n",
      "   macro avg       0.99      1.00      1.00      4556\n",
      "weighted avg       1.00      1.00      1.00      4556\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3450   12]\n",
      " [   3 1091]]\n",
      "\n",
      "Accuracy:  0.9967076382791923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       865\n",
      "           1       0.97      1.00      0.98       274\n",
      "\n",
      "    accuracy                           0.99      1139\n",
      "   macro avg       0.98      0.99      0.99      1139\n",
      "weighted avg       0.99      0.99      0.99      1139\n",
      "\n",
      "Confusion Matrix: \n",
      " [[856   9]\n",
      " [  1 273]]\n",
      "\n",
      "Accuracy:  0.9912203687445127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_bow = CountVectorizer(stop_words='english').fit_transform(emails['text'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages_bow, emails['spam'], test_size = 0.20,\n",
    "                                                    random_state = 0,\n",
    "                                                    stratify = emails['spam'])\n",
    "\n",
    "messages_bow.shape\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "test(MultinomialNB(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It acheived a pretty descent accuracy using the default parameter. Now let's check how it performs if we only encoding the presence information of the words in our text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3462\n",
      "           1       1.00      0.99      0.99      1094\n",
      "\n",
      "    accuracy                           1.00      4556\n",
      "   macro avg       1.00      1.00      1.00      4556\n",
      "weighted avg       1.00      1.00      1.00      4556\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3458    4]\n",
      " [   8 1086]]\n",
      "\n",
      "Accuracy:  0.9973661106233538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       865\n",
      "           1       0.97      0.99      0.98       274\n",
      "\n",
      "    accuracy                           0.99      1139\n",
      "   macro avg       0.98      0.99      0.99      1139\n",
      "weighted avg       0.99      0.99      0.99      1139\n",
      "\n",
      "Confusion Matrix: \n",
      " [[856   9]\n",
      " [  3 271]]\n",
      "\n",
      "Accuracy:  0.9894644424934153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_bow_b = CountVectorizer(stop_words='english', binary=True).fit_transform(emails['text'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages_bow_b, emails['spam'],\n",
    "                                                    test_size = 0.20, random_state = 0,\n",
    "                                                    stratify = emails['spam'])\n",
    "test(MultinomialNB(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't observe a large performance drop between these encoding methods. Now let's check how our own implementation performs compared to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      3462\n",
      "           1       0.98      1.00      0.99      1094\n",
      "\n",
      "    accuracy                           0.99      4556\n",
      "   macro avg       0.99      1.00      0.99      4556\n",
      "weighted avg       0.99      0.99      0.99      4556\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3441   21]\n",
      " [   4 1090]]\n",
      "\n",
      "Accuracy:  0.9945127304653204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       865\n",
      "           1       0.94      1.00      0.97       274\n",
      "\n",
      "    accuracy                           0.98      1139\n",
      "   macro avg       0.97      0.99      0.98      1139\n",
      "weighted avg       0.98      0.98      0.98      1139\n",
      "\n",
      "Confusion Matrix: \n",
      " [[847  18]\n",
      " [  1 273]]\n",
      "\n",
      "Accuracy:  0.9833187006145742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<naive_bayes.NaiveBayes_v0 at 0x109a79750>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from naive_bayes import NaiveBayes_v0\n",
    "test(NaiveBayes_v0(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, we acheived simliar performance with our naive implementation of Naive Bayes. Let's see whether our algorithm can generalize to other dataset rather than spam detection.\n",
    "\n",
    "https://github.com/aishajv/Unfolding-Naive-Bayes-from-Scratch/blob/master/%23%20Unfolding%20Na%C3%AFve%20Bayes%20from%20Scratch!%20Take-2%20%F0%9F%8E%AC.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = load_data('labeledTrainData.tsv', sep='\\t')\n",
    "testing_set = load_data('testData.tsv', sep='\\t')\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes:  [0 1]\n",
      "Total Number of Training Examples:  (25000,)\n",
      "Total Number of Testing Examples:  (25000,)\n"
     ]
    }
   ],
   "source": [
    "#getting training set examples labels\n",
    "print (\"Unique Classes: \",np.unique(training_set['sentiment']))\n",
    "print (\"Total Number of Training Examples: \",training_set['review'].shape)\n",
    "print (\"Total Number of Testing Examples: \",testing_set['review'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 74538)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(25000, 74538)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', binary=True)\n",
    "train_bow_b = vectorizer.fit_transform(training_set['review'])\n",
    "train_bow_b.shape\n",
    "# Loading the kaggle test dataset\n",
    "test_set = pd.read_csv('./datasets/testData.tsv',sep='\\t')\n",
    "test_bow_b = vectorizer.transform(testing_set['review'])\n",
    "test_bow_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_bow_b, training_set['sentiment'], \n",
    "                                                    test_size = 0.20, random_state = 0,\n",
    "                                                    stratify = training_set['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     10000\n",
      "           1       0.91      0.93      0.92     10000\n",
      "\n",
      "    accuracy                           0.92     20000\n",
      "   macro avg       0.92      0.92      0.92     20000\n",
      "weighted avg       0.92      0.92      0.92     20000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[9072  928]\n",
      " [ 658 9342]]\n",
      "\n",
      "Accuracy:  0.9207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      2500\n",
      "           1       0.84      0.89      0.87      2500\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.86      0.86      0.86      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2080  420]\n",
      " [ 268 2232]]\n",
      "\n",
      "Accuracy:  0.8624\n"
     ]
    }
   ],
   "source": [
    "clf = test(NaiveBayes_v0(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how MultinomialNB performs on movie review data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     10000\n",
      "           1       0.94      0.90      0.92     10000\n",
      "\n",
      "    accuracy                           0.92     20000\n",
      "   macro avg       0.92      0.92      0.92     20000\n",
      "weighted avg       0.92      0.92      0.92     20000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[9420  580]\n",
      " [1014 8986]]\n",
      "\n",
      "Accuracy:  0.9203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86      2500\n",
      "           1       0.88      0.84      0.86      2500\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.86      0.86      0.86      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2208  292]\n",
      " [ 402 2098]]\n",
      "\n",
      "Accuracy:  0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(MultinomialNB(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It's similar to our own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = clf.predict(test_bow_b.toarray())\n",
    "\n",
    "#writing results to csv to uplaoding on kaggle!\n",
    "kaggle_df = pd.DataFrame(data=np.column_stack([testing_set[\"id\"].values,test_pred.astype(int)])\n",
    "                         ,columns=[\"id\",\"sentiment\"])\n",
    "#kaggle_df.to_csv(\"./naive_bayes_model_take1.csv\",index=False)\n",
    "#print ('Predcitions Generated and saved to naive_bayes_model_take1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, we can submission our result to kaggle. Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our first attempt in implementing Naive Bayes is pretty naive in a sense that it only read binary feature and can only predict binary output. A more generalized Naive Bayes can read discrete feature and predict k categories. Let's see an example from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       480\n",
      "           1       0.99      1.00      0.99       584\n",
      "           2       1.00      0.99      1.00       594\n",
      "           3       1.00      0.99      1.00       599\n",
      "\n",
      "    accuracy                           1.00      2257\n",
      "   macro avg       1.00      1.00      1.00      2257\n",
      "weighted avg       1.00      1.00      1.00      2257\n",
      "\n",
      "Confusion Matrix: \n",
      " [[479   0   0   1]\n",
      " [  0 583   1   0]\n",
      " [  0   2 591   1]\n",
      " [  0   3   0 596]]\n",
      "\n",
      "Accuracy:  0.9964554718653079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       319\n",
      "           1       0.95      0.97      0.96       389\n",
      "           2       0.96      0.92      0.94       396\n",
      "           3       0.93      0.96      0.95       398\n",
      "\n",
      "    accuracy                           0.94      1502\n",
      "   macro avg       0.94      0.94      0.94      1502\n",
      "weighted avg       0.94      0.94      0.94      1502\n",
      "\n",
      "Confusion Matrix: \n",
      " [[289   3   5  22]\n",
      " [  5 376   6   2]\n",
      " [ 11  13 366   6]\n",
      " [  5   4   5 384]]\n",
      "\n",
      "Accuracy:  0.9420772303595206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "     categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "     categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "twenty_train.target_names\n",
    "len(twenty_train.data)\n",
    "len(twenty_train.filenames)\n",
    "X_train = vectorizer.fit_transform(twenty_train.data)\n",
    "X_test = vectorizer.transform(twenty_test.data)\n",
    "y_train = twenty_train.target\n",
    "y_test = twenty_test.target\n",
    "\n",
    "test(MultinomialNB(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       480\n",
      "           1       0.99      1.00      1.00       584\n",
      "           2       0.99      1.00      1.00       594\n",
      "           3       0.99      0.99      0.99       599\n",
      "\n",
      "    accuracy                           0.99      2257\n",
      "   macro avg       0.99      0.99      0.99      2257\n",
      "weighted avg       0.99      0.99      0.99      2257\n",
      "\n",
      "Confusion Matrix: \n",
      " [[472   0   0   8]\n",
      " [  0 582   2   0]\n",
      " [  0   1 593   0]\n",
      " [  0   2   1 596]]\n",
      "\n",
      "Accuracy:  0.9937970757642889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86       319\n",
      "           1       0.97      0.92      0.94       389\n",
      "           2       0.91      0.95      0.93       396\n",
      "           3       0.83      0.98      0.90       398\n",
      "\n",
      "    accuracy                           0.91      1502\n",
      "   macro avg       0.92      0.90      0.91      1502\n",
      "weighted avg       0.92      0.91      0.91      1502\n",
      "\n",
      "Confusion Matrix: \n",
      " [[246   4  12  57]\n",
      " [  2 357  21   9]\n",
      " [  2   7 375  12]\n",
      " [  2   1   5 390]]\n",
      "\n",
      "Accuracy:  0.9107856191744341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<naive_bayes.NaiveBayes_v1 at 0x11e937f10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from naive_bayes import NaiveBayes_v1\n",
    "test(NaiveBayes_v1(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that although we got similar training results, but our testing is not good as sklearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
