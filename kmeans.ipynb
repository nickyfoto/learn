{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing KMeans, Step by Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cluster\n",
    "from kmeans import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[10.,  2.],\n",
       "       [ 1.,  2.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "              [10, 2], [10, 4], [10, 0]])\n",
    "n_clusters = 2\n",
    "kmeans = cluster.KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "kmeans.labels_\n",
    "kmeans.predict([[0, 0], [12, 3]])\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from inference. KMeans require us to give the number of clusters. After fitting with data, we found `n` centers and labeling new data belongs to the center that it has the minimum distance. Note that, in general, centers are not points from `X`, although they live in the same space.\n",
    "\n",
    "The first step is to initialize `n` centers. We use `np.random.shuffle` to shuffle the indices of `X` and then choose top `n`. Note that if `X` contains duplicate rows, you need to select `n` distinct centers. One way to acheive this is to use \n",
    "\n",
    "```python\n",
    "unique_X = np.unique(X, axis=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "              [10, 2], [10, 4], [10, 0]])\n",
    "m, _ = X.shape\n",
    "indices = np.arange(m)\n",
    "np.random.shuffle(indices)\n",
    "cluster_centers_ = X[indices[:n_clusters]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we initialized centers, we iteratively update our centers and labels so that the sum of squared distance of between our training example and cluster centers are miminized. This is also called **inertia**.\n",
    "\n",
    "For every iteration, we build labels to be a `(n,1)` array. And then calculate the mean value of example belong to that cluster and assign these mean value to be new centers.\n",
    "\n",
    "```python\n",
    "clusters = np.arange(n_clusters).reshape(n_clusters, 1)\n",
    "cluster_centers_ = np.apply_along_axis(\n",
    "                                lambda cluster: X[labels_ == cluster.item()].mean(axis=0), \n",
    "                                axis=1, arr=clusters)\n",
    "```\n",
    "\n",
    "Put all these together, we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[10.,  2.],\n",
       "       [ 1.,  2.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 100\n",
    "for it in range(max_iter):\n",
    "    dists = distance.cdist(X, cluster_centers_, metric='euclidean')\n",
    "    labels_ = np.argmin(dists, axis=1)\n",
    "    clusters = np.arange(n_clusters).reshape(n_clusters, 1)\n",
    "    cluster_centers_ = np.apply_along_axis(\n",
    "                                lambda cluster: X[labels_ == cluster.item()].mean(axis=0), \n",
    "                                axis=1, arr=clusters)\n",
    "labels_\n",
    "cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(distance.cdist([[0, 0], [12, 3]], cluster_centers_, metric='euclidean'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, a key point in the iteration is how to calculate distance between two points. For efficiency purpose, we use [`distance.cdist`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html) from scipy. You can also write your own distance function as:\n",
    "\n",
    "```python\n",
    "def pairwise_dist(x, y):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: N x D numpy array\n",
    "        y: M x D numpy array\n",
    "    Return:\n",
    "        dist: N x M array, where dist2[i, j] is the euclidean distance between \n",
    "        x[i, :] and y[j, :]\n",
    "    \"\"\"\n",
    "    return (np.sum((x[np.newaxis,:] - y[:, np.newaxis])**2, axis=-1)**0.5).T\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap all these functionalities in a class, we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[10.,  2.],\n",
       "       [ 1.,  2.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "kmeans.labels_\n",
    "kmeans.cluster_centers_\n",
    "kmeans.predict([[0, 0], [12, 3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/clustering.html#k-means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
