{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by Step Implement Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've see the [theory](https://nickyfoto.github.io/blog/entries/linear-regression) part of Linear Regression, now let's see how to implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from evaluation import test\n",
    "from utils import load_data, predict_image, scatter_plot, contour_plot\n",
    "from utils import plot_boundary, load_cat_dataset, load_iris_2D\n",
    "from utils import plot_costs\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# from lr import LogisticRegression\n",
    "from lm import LinearRegression, Ridge, SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you will learn\n",
    "\n",
    "- How to implement Least Mean Squares linear regression.\n",
    "- How to implement stochastic gradient descent linear regression.\n",
    "- How to evaluate the performance using coefficient of determination, usually denoted as $R^2$.\n",
    "- How to implement normal equation linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMS algorithm\n",
    "\n",
    "Take an example from sklearn, we can see that the model learned the `coef_` and `intercept_` correctly. How did it do that? There are many ways the model can learn the weights. The first one we introduce is Least Mean Squares (LMS) update rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "# y = 1 * x_0 + 2 * x_1 + 3\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "reg = linear_model.LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([1., 2.]), 3.0000000000000018)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([16.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X, y)\n",
    "reg.coef_, reg.intercept_ \n",
    "reg.predict(np.array([[3, 5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given `X`, `coef_` and `intercept_` predict new example using\n",
    "\n",
    "```python\n",
    "np.dot(X, coef_) + intercept_\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the only difference with logistic regression is the decision function we use. Here we discard the sigmoid function and directly use\n",
    "\n",
    "```python\n",
    "np.dot(X, coef_.T) + intercept_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.00081836, 1.99989287]]), array([2.99890748]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n_features = X.shape\n",
    "coef_ = np.zeros(shape=(1, n_features))\n",
    "intercept_ = np.zeros(shape=(1,))\n",
    "y.shape = (m, 1)\n",
    "max_iter = 1000\n",
    "learning_rate = 1e-1\n",
    "for step in range(max_iter):  \n",
    "    preds = np.dot(X, coef_.T) + intercept_\n",
    "    error = preds - y\n",
    "    gradient = np.dot(X.T, error) \n",
    "    coef_ -= learning_rate * gradient.T / m\n",
    "    intercept_ -= learning_rate * error.sum() / m\n",
    "coef_, intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the weights we learned to predict new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.0008269]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9999999582739324"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array([[3,5]]), coef_.T) + intercept_\n",
    "r2_score(y_true=y.flatten(), y_pred = np.dot(X, coef_.T) + intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent linear regression\n",
    "\n",
    "Note that to proximate the target value, we need 1000 epochs. Is there a better way? Similar to logistic regression, we can try stochastic gradient descent.\n",
    "\n",
    "```python\n",
    "pred = np.dot(x, coef_.T) + intercept_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 2.]]), array([3.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_ = np.zeros(shape=(1, n_features))\n",
    "max_iter = 600\n",
    "intercept_ = np.zeros(shape=(1,))\n",
    "for i in range(max_iter):\n",
    "    for idx, x in enumerate(X):\n",
    "        pred = np.dot(x, coef_.T) + intercept_\n",
    "        error = pred - y[idx]\n",
    "        gradient = x * error\n",
    "        coef_ -= learning_rate * gradient.T\n",
    "        intercept_ -= learning_rate * error\n",
    "coef_, intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update weights on every training example, hence it reduces the number of iteration to converge. To wrap up all our functionality in our own `SGDRegressor`, we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8,  9, 11])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(batch=False, c_lambda=0, fit_intercept=True, learning_rate=0.1,\n",
       "             max_iter=1000, penalty=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([[1., 2.]]), array([3.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[16.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "y\n",
    "sgdreg = sgdreg = SGDRegressor(learning_rate=1e-1)\n",
    "sgdreg.fit(X, y)\n",
    "sgdreg.score(X, y)\n",
    "sgdreg.coef_, sgdreg.intercept_ \n",
    "sgdreg.predict(np.array([[3, 5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The normal equations\n",
    "\n",
    "According to the [normal equation](https://nickyfoto.github.io/blog/entries/linear-regression#the-normal-equation), we can analytically solve for $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 2.],\n",
       "       [1., 2., 2.],\n",
       "       [1., 2., 3.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept = np.ones((X.shape[0], 1))\n",
    "X = np.hstack((intercept, X))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we doing so, remember to add the intercept part so that our line doesn't have to be lie in the origin point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 1., 2.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "theta.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytically solving $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.,  8.,  9., 11.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X, theta).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions using $\\theta$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
