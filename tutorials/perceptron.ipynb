{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "\n",
    "from learn import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another classification algorithm you might hear of called perceptron. The [notes](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html) of sklearn's Perceptron state that the implementation of Perceptron is the same with `SGDClassifier`. In fact, `Perceptron()` is equivalent to `SGDClassifier(loss=\"perceptron\", eta0=1, learning_rate=\"constant\", penalty=None)`. You can see the evidence from the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9261862917398945"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import Perceptron\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=1, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='constant', loss='perceptron',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty=None,\n",
       "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9261862917398945"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss=\"perceptron\", eta0=1, learning_rate=\"constant\", penalty=None,\n",
    "                                 random_state=0,shuffle=True)\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only change we need to make from Logistic regression to Perceptron is the decision function we output after the dot product. Here, if the dot product is larger or equal to 0, we output 1, otherwise we output 0.\n",
    "\n",
    "```python\n",
    "pred = np.dot(X, self.coef_.T) + self.intercept_\n",
    "return np.where(pred >= 0, 1, 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(c_lambda=0, fit_intercept=True, learning_rate=0.2,\n",
       "                   loss='perceptron', max_iter=1000, penalty=None,\n",
       "                   print_cost=False, random_state=0, sgd=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9314586994727593"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(sgd=True, max_iter=1000, learning_rate=0.2, loss='perceptron', random_state=0)\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
