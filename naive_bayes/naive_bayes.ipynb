{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/randerson112358/Python/blob/master/Email_Spam_Detection/Email_Spam_Detection.ipynb\n",
    "\n",
    "Data Source: https://www.kaggle.com/balakishan77/spam-or-ham-email-classification/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5728, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('emails.csv')\n",
    "df.head(5)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates\n",
    "df.drop_duplicates(inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode text using `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t3\n",
      "  (0, 4)\t2\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t4\n",
      "  (1, 1)\t1\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "message0 = 'hello world hello hello world play'\n",
    "message1 = 'test test test test one hello'\n",
    "\n",
    "#Convert a collection of text documents to a matrix of token counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform([message0, message1])\n",
    "print(bow)\n",
    "print(type(bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `CountVectorizer` returns a sparse matrix encoding our texts with the number of times a particular word occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'one', 'play', 'test', 'world']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1, 0, 2],\n",
       "       [1, 1, 0, 4, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "[vocabulary[i] for i in sorted([v for k,v in vectorizer.vocabulary_.items()])]\n",
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can see how the encoding information is saved in a sparse matrix. For `message0`, on indices [0,4,2] you have values [3,2,1].\n",
    "\n",
    "If we set `binary=True` when encoding messages, our encoder only records the whether the word is present or not, ignoring the numbber of occurance. For our first implementation of `NaiveBayes`, we will simply encode the presence of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 1)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1],\n",
       "       [1, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_b = CountVectorizer(binary=True)\n",
    "bow_b = vectorizer_b.fit_transform([message0, message1])\n",
    "print(bow_b)\n",
    "bow_b.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with MultinomialNB from sklearn\n",
    "\n",
    "Before implementing our own learner, let's check the performance of `MultinomialNB` from sklearn. Here we remove the stop_words when vectorizing our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 36996)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3462\n",
      "           1       0.99      1.00      0.99      1094\n",
      "\n",
      "    accuracy                           1.00      4556\n",
      "   macro avg       0.99      1.00      1.00      4556\n",
      "weighted avg       1.00      1.00      1.00      4556\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3450   12]\n",
      " [   3 1091]]\n",
      "\n",
      "Accuracy:  0.9967076382791923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       865\n",
      "           1       0.97      1.00      0.98       274\n",
      "\n",
      "    accuracy                           0.99      1139\n",
      "   macro avg       0.98      0.99      0.99      1139\n",
      "weighted avg       0.99      0.99      0.99      1139\n",
      "\n",
      "Confusion Matrix: \n",
      " [[856   9]\n",
      " [  1 273]]\n",
      "\n",
      "Accuracy:  0.9912203687445127\n"
     ]
    }
   ],
   "source": [
    "messages_bow = CountVectorizer(stop_words='english').fit_transform(df['text'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages_bow, df['spam'], test_size = 0.20, random_state = 0,\n",
    "                                                   stratify = df['spam'])\n",
    "\n",
    "messages_bow.shape\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the model on the training data set\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(X_train)\n",
    "print(classification_report(y_train ,pred ))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_train,pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_train,pred))\n",
    "\n",
    "pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test ,pred ))\n",
    "\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test,pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It acheived a pretty descent accuracy using the default parameter. Now let's check how it performs if we only encoding the presence information of the words in our text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3462\n",
      "           1       1.00      0.99      0.99      1094\n",
      "\n",
      "    accuracy                           1.00      4556\n",
      "   macro avg       1.00      1.00      1.00      4556\n",
      "weighted avg       1.00      1.00      1.00      4556\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3458    4]\n",
      " [   8 1086]]\n",
      "\n",
      "Accuracy:  0.9973661106233538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       865\n",
      "           1       0.97      0.99      0.98       274\n",
      "\n",
      "    accuracy                           0.99      1139\n",
      "   macro avg       0.98      0.99      0.99      1139\n",
      "weighted avg       0.99      0.99      0.99      1139\n",
      "\n",
      "Confusion Matrix: \n",
      " [[856   9]\n",
      " [  3 271]]\n",
      "\n",
      "Accuracy:  0.9894644424934153\n"
     ]
    }
   ],
   "source": [
    "messages_bow_b = CountVectorizer(stop_words='english', binary=True).fit_transform(df['text'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages_bow_b, df['spam'], test_size = 0.20, random_state = 0,\n",
    "                                                    stratify = df['spam'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate the model on the training data set\n",
    "pred = classifier.predict(X_train)\n",
    "print(classification_report(y_train ,pred ))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_train,pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_train,pred))\n",
    "\n",
    "pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test ,pred ))\n",
    "\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test,pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't observe a large performance drop between these encoding methods. Now let's check how our own implementation performs compared to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      3462\n",
      "           1       0.98      1.00      0.99      1094\n",
      "\n",
      "    accuracy                           0.99      4556\n",
      "   macro avg       0.99      1.00      0.99      4556\n",
      "weighted avg       0.99      0.99      0.99      4556\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3441   21]\n",
      " [   4 1090]]\n",
      "\n",
      "Accuracy:  0.9945127304653204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       865\n",
      "           1       0.94      1.00      0.97       274\n",
      "\n",
      "    accuracy                           0.98      1139\n",
      "   macro avg       0.97      0.99      0.98      1139\n",
      "weighted avg       0.98      0.98      0.98      1139\n",
      "\n",
      "Confusion Matrix: \n",
      " [[847  18]\n",
      " [  1 273]]\n",
      "\n",
      "Accuracy:  0.9833187006145742\n"
     ]
    }
   ],
   "source": [
    "from naive_bayes import NaiveBayes_v0\n",
    "clf = NaiveBayes_v0()\n",
    "clf.fit(X_train.toarray(), y_train)\n",
    "\n",
    "pred = clf.predict(X_train.toarray())\n",
    "print(classification_report(y_train ,pred ))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_train,pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_train,pred))\n",
    "\n",
    "pred = clf.predict(X_test.toarray())\n",
    "print(classification_report(y_test ,pred ))\n",
    "\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test,pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, we acheived simliar performance with our naive implementation of Naive Bayes. Let's see whether our algorithm can generalize to other dataset rather than spam detection.\n",
    "\n",
    "https://github.com/aishajv/Unfolding-Naive-Bayes-from-Scratch/blob/master/%23%20Unfolding%20Na%C3%AFve%20Bayes%20from%20Scratch!%20Take-2%20%F0%9F%8E%AC.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set=pd.read_csv('./labeledTrainData.tsv',sep='\\t')\n",
    "testing_set=pd.read_csv('./testData.tsv',sep='\\t')\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes:  [0 1]\n",
      "Total Number of Training Examples:  (25000,)\n",
      "Total Number of Testing Examples:  (25000,)\n"
     ]
    }
   ],
   "source": [
    "#getting training set examples labels\n",
    "print (\"Unique Classes: \",np.unique(training_set['sentiment']))\n",
    "print (\"Total Number of Training Examples: \",training_set['review'].shape)\n",
    "print (\"Total Number of Testing Examples: \",testing_set['review'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 74538)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(25000, 74538)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', binary=True)\n",
    "train_bow_b = vectorizer.fit_transform(training_set['review'])\n",
    "train_bow_b.shape\n",
    "# Loading the kaggle test dataset\n",
    "test_set = pd.read_csv('./testData.tsv',sep='\\t')\n",
    "test_bow_b = vectorizer.transform(testing_set['review'])\n",
    "test_bow_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_bow_b, training_set['sentiment'], \n",
    "                                                    test_size = 0.20, random_state = 0,\n",
    "                                                    stratify = training_set['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     10000\n",
      "           1       0.91      0.93      0.92     10000\n",
      "\n",
      "    accuracy                           0.92     20000\n",
      "   macro avg       0.92      0.92      0.92     20000\n",
      "weighted avg       0.92      0.92      0.92     20000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[9072  928]\n",
      " [ 658 9342]]\n",
      "\n",
      "Accuracy:  0.9207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      2500\n",
      "           1       0.84      0.89      0.87      2500\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.86      0.86      0.86      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2080  420]\n",
      " [ 268 2232]]\n",
      "\n",
      "Accuracy:  0.8624\n"
     ]
    }
   ],
   "source": [
    "clf = NaiveBayes_v0()\n",
    "clf.fit(X_train.toarray(), y_train)\n",
    "\n",
    "pred = clf.predict(X_train.toarray())\n",
    "print(classification_report(y_train ,pred ))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_train,pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_train,pred))\n",
    "\n",
    "pred = clf.predict(X_test.toarray())\n",
    "print(classification_report(y_test ,pred ))\n",
    "\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test,pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predcitions Generated and saved to naive_bayes_model_take1.csv\n"
     ]
    }
   ],
   "source": [
    "test_pred = clf.predict(test_bow_b.toarray())\n",
    "\n",
    "#writing results to csv to uplaoding on kaggle!\n",
    "kaggle_df = pd.DataFrame(data=np.column_stack([testing_set[\"id\"].values,test_pred.astype(int)])\n",
    "                         ,columns=[\"id\",\"sentiment\"])\n",
    "kaggle_df.to_csv(\"./naive_bayes_model_take1.csv\",index=False)\n",
    "print ('Predcitions Generated and saved to naive_bayes_model_take1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./kaggle1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, we can submission our result to kaggle. Not bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
