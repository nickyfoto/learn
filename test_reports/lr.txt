Start testing

    Generated data example from
    https://github.com/beckernick/logistic_regression_from_scratch/blob/master/logistic_regression_scratch.ipynb
    
mylearn LogisticRegression(C=0, fit_intercept=True, learning_rate=0.1,
                   num_iterations=300000, penalty=None, print_cost=False,
                   steps=10)
sklearn LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='none',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
mylearn Confusion Matrix: 
 [[3976   24]
 [  19 3981]]

sklearn Confusion Matrix: 
 [[3976   24]
 [  19 3981]]

mylearn Training Accuracy: 0.994625

sklearn Training Accuracy: 0.994625


comparing intercept_
mylearn: [-14.18266851]
sklearn: [-14.63223973]

comparing coef_
mylearn: [[-4.84672859  8.21517668]]
sklearn: [[-4.99355613  8.4680955 ]]

================================================================================
mylearn LogisticRegressionSGD(C=0, fit_intercept=True, learning_rate=0.01,
                      num_iterations=500, penalty=None, print_cost=False)
sklearn LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='none',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
mylearn Confusion Matrix: 
 [[3976   24]
 [  20 3980]]

sklearn Confusion Matrix: 
 [[3976   24]
 [  19 3981]]

mylearn Training Accuracy: 0.9945

sklearn Training Accuracy: 0.994625


comparing intercept_
mylearn: [-14.45567905]
sklearn: [-14.63223973]

comparing coef_
mylearn: [[-4.94405277  8.33901583]]
sklearn: [[-4.99355613  8.4680955 ]]

================================================================================
mylearn LogisticRegression(C=3.3333333333333335, fit_intercept=True, learning_rate=0.1,
                   num_iterations=300000, penalty='l2', print_cost=False,
                   steps=10)
sklearn LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
mylearn Confusion Matrix: 
 [[3977   23]
 [  19 3981]]

sklearn Confusion Matrix: 
 [[3977   23]
 [  19 3981]]

mylearn Training Accuracy: 0.99475

sklearn Training Accuracy: 0.99475


comparing intercept_
mylearn: [-9.02026004]
sklearn: [-9.02026122]

comparing coef_
mylearn: [[-2.88406556  5.18823839]]
sklearn: [[-2.8840657  5.188239 ]]

================================================================================
mylearn LogisticRegressionSGD(C=3.3333333333333335, fit_intercept=True,
                      learning_rate=0.01, num_iterations=500, penalty='l2',
                      print_cost=False)
sklearn LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
mylearn Confusion Matrix: 
 [[3977   23]
 [  23 3977]]

sklearn Confusion Matrix: 
 [[3977   23]
 [  19 3981]]

mylearn Training Accuracy: 0.99425

sklearn Training Accuracy: 0.99475


comparing intercept_
mylearn: [-9.0555806]
sklearn: [-9.02026122]

comparing coef_
mylearn: [[-2.90430589  5.14692423]]
sklearn: [[-2.8840657  5.188239 ]]

================================================================================

    load iris and combine label 1, 2 into 1
    only use the first two features of X
    
mylearn LogisticRegression(C=0, fit_intercept=True, learning_rate=0.1,
                   num_iterations=300000, penalty=None, print_cost=False,
                   steps=10)
sklearn LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='none',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
mylearn Confusion Matrix: 
 [[40  0]
 [ 0 80]]

sklearn Confusion Matrix: 
 [[40  0]
 [ 0 80]]

mylearn Training Accuracy: 1.0

sklearn Training Accuracy: 1.0


comparing intercept_
mylearn: [-26.26209792]
sklearn: [-259.59146071]

comparing coef_
mylearn: [[ 12.54736436 -13.32376475]]
sklearn: [[ 94.93677687 -78.07940563]]

================================================================================
mylearn LogisticRegressionSGD(C=0, fit_intercept=True, learning_rate=0.01,
                      num_iterations=500, penalty=None, print_cost=False)
sklearn LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='none',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
mylearn Confusion Matrix: 
 [[39  1]
 [ 0 80]]

sklearn Confusion Matrix: 
 [[40  0]
 [ 0 80]]

mylearn Training Accuracy: 0.9916666666666667

sklearn Training Accuracy: 1.0


comparing intercept_
mylearn: [-2.12541922]
sklearn: [-259.59146071]

comparing coef_
mylearn: [[ 5.07925838 -8.20235308]]
sklearn: [[ 94.93677687 -78.07940563]]

================================================================================
mylearn LogisticRegression(C=3.3333333333333335, fit_intercept=True, learning_rate=0.1,
                   num_iterations=300000, penalty='l2', print_cost=False,
                   steps=10)
sklearn LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
mylearn Confusion Matrix: 
 [[40  0]
 [ 0 80]]

sklearn Confusion Matrix: 
 [[40  0]
 [ 0 80]]

mylearn Training Accuracy: 1.0

sklearn Training Accuracy: 1.0


comparing intercept_
mylearn: [-5.5569208]
sklearn: [-5.55692049]

comparing coef_
mylearn: [[ 2.06883297 -1.75577685]]
sklearn: [[ 2.06883293 -1.75577689]]

================================================================================
mylearn LogisticRegressionSGD(C=3.3333333333333335, fit_intercept=True,
                      learning_rate=0.01, num_iterations=500, penalty='l2',
                      print_cost=False)
sklearn LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
mylearn Confusion Matrix: 
 [[39  1]
 [ 0 80]]

sklearn Confusion Matrix: 
 [[40  0]
 [ 0 80]]

mylearn Training Accuracy: 0.9916666666666667

sklearn Training Accuracy: 1.0


comparing intercept_
mylearn: [-3.7137379]
sklearn: [-5.55692049]

comparing coef_
mylearn: [[ 1.84864939 -1.96763295]]
sklearn: [[ 2.06883293 -1.75577689]]

================================================================================
End testing
247.67556405067444
